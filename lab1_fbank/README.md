# å®žéªŒ1è¿›åº¦ä¸Žé—®é¢˜è®°å½•

## å®žéªŒæè¿°
1. ç»™å®šä¸€æ®µè¯­éŸ³ä¿¡å·ï¼ˆ16KHZ Wav PCMï¼‰ï¼Œæå–80ç»´Log Mel Spectrogramï¼ˆFbankï¼‰ç‰¹å¾ï¼Œå¹¶ç”»å›¾ã€‚
2. é€‰åšå®žéªŒå†…å®¹: æŠ½å–spectrogramç‰¹å¾, å¹¶å¯è§†åŒ–~~å·²å®Œæˆ~~, æŠ½å–MFCCç‰¹å¾ï¼Œå¹¶å¯è§†åŒ–~~å·²å®Œæˆ~~, æŠ½å–PLPç‰¹å¾ï¼Œå¹¶å¯è§†åŒ–~~å·²å®Œæˆ~~ã€‚
## å®žéªŒè¿‡ç¨‹
å®žéªŒè¿‡ç¨‹åŸºæœ¬æŒ‰ç…§ä¸‹å›¾æ‰€ç¤ºçš„å®žéªŒæ­¥éª¤è¿›è¡Œå®žéªŒ   

![202303090804169|500](https://image-1305894911.cos.ap-beijing.myqcloud.com/Obsidian/202303090805998.png)
### Fbankç‰¹å¾æŠ½å–

### å®žéªŒä»£ç 

```python
# step 1: è¯»å…¥è¯­éŸ³
sample_rate, signal = wavfile.read('./speech_feature/wav/æˆ‘çˆ±å—å¼€.wav')
# step 2: é¢„åŠ é‡
sig = pre_emphasis(signal)
# step 3: åˆ†å¸§
frame_sig = framing(sig, sample_rate)
# step 4: åŠ çª—
frame_sig = add_window(frame_sig, sample_rate)
# step 5: å¿«é€Ÿå‚…é‡Œå¶å˜æ¢
mag_frames = my_fft(frame_sig)
# step 6: å¹…å€¼å¹³æ–¹, å˜ä¸ºåŠŸçŽ‡è°±
frame_pow = stft(frame_sig)
# step 7: melæ»¤æ³¢å™¨: æ³¨æ„æ­¤æ—¶melæ»¤æ³¢å™¨è¦è®¾ç½®ä¸º80ç»´
filter_banks = mel_filter(frame_pow, sample_rate, n_filter=80)
# step 8: å¯¹æ•°åŠŸçŽ‡
filter_banks = log_pow(filter_banks)
# ç»˜å›¾
plot_spectrogram(filter_banks.T, "Filter Banks", "melå›¾")
```
### å®žéªŒç»“æžœ

![output.png|500](https://image-1305894911.cos.ap-beijing.myqcloud.com/Obsidian/202303152238042.png)
### å…¶å®ƒç‰¹å¾æŠ½å–
### å®žéªŒä»£ç 
ä»¥ä¸‹ä»£ç æ˜¯æŠ½å–spectrogramç‰¹å¾, å¹¶å¯è§†åŒ–

```python
# ç›´æŽ¥å¯¹æ•°åŠŸçŽ‡, ä¸è¿›è¡Œmelæ»¤æ³¢
spec = log_pow(frame_pow)
# ç»˜å›¾
plot_spectrogram(spec, "spectrogram", "spectiogramå¯è§†åŒ–")
```

ä»¥ä¸‹ä»£ç æ˜¯æŠ½å–MFCCç‰¹å¾, å¹¶å¯è§†åŒ–, å…¶ä¸­ç¦»æ•£ä½™å¼¦å˜æ¢åœ¨è¿™é‡Œç±»ä¼¼é€†å‚…é‡Œå¶å˜æ¢çš„ä½œç”¨ã€‚

```python
# ç¦»æ•£ä½™å¼¦å˜æ¢
mfcc = discrete_cosine_transform(filter_banks)
# ç»˜å›¾
plot_spectrogram(mfcc, "mfcc", "mfccå¯è§†åŒ–")
```

ä»¥ä¸‹ä»£ç æ˜¯æŠ½å–PLPç‰¹å¾, å¹¶å¯è§†åŒ–, åœ¨PLPç‰¹å¾çš„æŠ½å–ä¸­å€Ÿé‰´äº†`Spafe`åº“å‡½æ•°ä¸­çš„ä»£ç , ä½¿ç”¨äº†Spafeåº“å‡½æ•°ä¸­çš„APIæ¥å¸®åŠ©æˆ‘ä»¬å®žçŽ°PLPç‰¹å¾æŠ½å–

```python
from spafe.features.lpc import __lpc_helper, lpc2lpcc
from spafe.utils.vis import show_features
# a. èŽ·å–ä¸€ä¸ªberkæ»¤æ³¢å™¨ bark_filter_banks
fbanks = bark_filter_banks()

# b. è¿›è¡Œbarkæ»¤æ³¢
auditory_spectrum = np.dot(a=frame_pow, b=fbanks.T)

# c. ç­‰å“åº¦é¢„åŠ é‡
E = lambda w: ((w**2 + 56.8 * 10**6) * w**4) / (
    (w**2 + 6.3 * 10**6)
    * (w**2 + 0.38 * 10**9)
    * (w**6 + 9.58 * 10**26)
)
Y = [E(w) for w in auditory_spectrum]

# d. å¼ºåº¦å“åº¦è½¬æ¢
L = np.abs(Y) ** (1 / 3)

# e. ifft é€†å‚…é‡Œå¶å˜æ¢
inverse_fourrier_transform = np.absolute(np.fft.ifft(L, 512))

# f. compute lpcs and lpccs çº¿æ€§é¢„æµ‹ï¼ˆlpc)
lpcs = np.zeros((L.shape[0], 13))
lpccs = np.zeros((L.shape[0], 13))
for i in range(L.shape[0]):
    a, e = __lpc_helper(inverse_fourrier_transform[i, :], 13 - 1)
    lpcs[i, :] = a
    lpcc_coeffs = lpc2lpcc(a, e, 13)
    lpccs[i, :] = np.array(lpcc_coeffs)

# ç»˜å›¾
show_features(lpccs, "Perceptual linear predictions", "PLP Index", "Frame Index")
```

åœ¨PLPç‰¹å¾çš„æŠ½å–è¿‡ç¨‹ä¸­, æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨å¯¹åº”çš„åº“å‡½æ•°ç›´æŽ¥ç”ŸæˆPLPç‰¹å¾

```python
# spafeåº“plpæŠ½å–
from scipy.io.wavfile import read
from spafe.features.rplp import plp
from spafe.utils.preprocessing import SlidingWindow
from spafe.utils.vis import show_features

plps = plp(signal)

# visualize features
show_features(plps, "Perceptual linear predictions", "PLP Index", "Frame Index")
```

å¦å¤–, æˆ‘ä»¬ä¹Ÿå¯ä»¥å€ŸåŠ©`spafe`åº“å‡½æ•°å®žçŽ°CQCCç‰¹å¾æå–

```python
from spafe.features.cqcc import cqt_spectrogram
from spafe.utils.vis import show_spectrogram
from spafe.utils.preprocessing import SlidingWindow
from scipy.io.wavfile import read

# read audio
fpath = "speech_feature\wav\æˆ‘çˆ±å—å¼€.wav"
fs, sig = read(fpath)

# compute spectrogram
qSpec = cqt_spectrogram(sig,
                        fs=fs,
                        pre_emph=0,
                        pre_emph_coeff=0.97,
                        window=SlidingWindow(0.03, 0.015, "hamming"),
                        nfft=2048,
                        low_freq=0,
                        high_freq=fs/2)

# visualize spectrogram
show_spectrogram(qSpec,
                 fs=fs,
                 xmin=0,
                 xmax=len(sig)/fs,
                 ymin=0,
                 ymax=(fs/2)/1000,
                 dbf=80.0,
                 xlabel="Time (s)",
                 ylabel="Frequency (kHz)",
                 title="CQT spectrogram (dB)",
                 cmap="jet")
```
### å®žéªŒç»“æžœ
spectrogramç‰¹å¾æŠ½å–å¯è§†åŒ–ç»“æžœ: 

![202303152252921|500](https://image-1305894911.cos.ap-beijing.myqcloud.com/Obsidian/202303152252921.png)

MFCCç‰¹å¾æŠ½å–å¯è§†åŒ–ç»“æžœ: 

![202303152253105|500](https://image-1305894911.cos.ap-beijing.myqcloud.com/Obsidian/202303152253105.png)

PLPç‰¹å¾æŠ½å–å¯è§†åŒ–ç»“æžœ: 

![202303152248337|500](https://image-1305894911.cos.ap-beijing.myqcloud.com/Obsidian/202303152248337.png)

## å‚è€ƒèµ„æ–™
å…¨éƒ¨å®žéªŒä»£ç å·²ä¸Šä¼  [æˆ‘çš„è®¡ç®—æœºè¯­éŸ³å¤„ç†æŠ€æœ¯githubä»“åº“](https://github.com/NK-MXD/ComputerSpeech/tree/main)

> [!ob-example] å‚è€ƒèµ„æ–™
> + åšæ–‡ [(72æ¡æ¶ˆæ¯) Pythonè¯­éŸ³ä¿¡å·ç‰¹å¾-æ„ŸçŸ¥çº¿æ€§é¢„æµ‹ç³»æ•°PLP_è™¾ç±³çš„åœˆçš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/weixin_42485817/article/details/107590846)
> + åšæ–‡ [(72æ¡æ¶ˆæ¯) è¯­éŸ³è¯†åˆ«-ç‰¹å¾æå–(Pythonå®žçŽ°ï¼‰WuJia_çš„åšå®¢-CSDNåšå®¢](https://blog.csdn.net/WuJia_/article/details/107044859)
> + æ–‡æ¡£ [ðŸ“„ API documentation â€” ðŸ§  SuperKogito/Spafe 0.3.2 documentation](https://superkogito.github.io/spafe/api_documentation.html)


