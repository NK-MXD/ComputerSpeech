{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 5s 0us/step\n",
      "step: 200, loss: 3.727396, accuracy: 0.146406\n",
      "step: 400, loss: 3.015347, accuracy: 0.140078\n",
      "step: 600, loss: 2.778035, accuracy: 0.143281\n",
      "step: 800, loss: 2.659399, accuracy: 0.144805\n",
      "step: 1000, loss: 2.588017, accuracy: 0.145781\n",
      "step: 1200, loss: 2.540430, accuracy: 0.146016\n",
      "step: 1400, loss: 2.506387, accuracy: 0.144888\n",
      "step: 1600, loss: 2.480855, accuracy: 0.144785\n",
      "step: 1800, loss: 2.464123, accuracy: 0.144740\n",
      "step: 2000, loss: 2.447985, accuracy: 0.145047\n",
      "step: 2200, loss: 2.434780, accuracy: 0.146463\n",
      "step: 2400, loss: 2.423776, accuracy: 0.146042\n",
      "step: 2600, loss: 2.414465, accuracy: 0.146334\n",
      "step: 2800, loss: 2.406485, accuracy: 0.146529\n",
      "step: 3000, loss: 2.399568, accuracy: 0.147146\n",
      "step: 3200, loss: 2.393516, accuracy: 0.147861\n",
      "step: 3400, loss: 2.388176, accuracy: 0.148116\n",
      "step: 3600, loss: 2.383429, accuracy: 0.148125\n",
      "step: 3800, loss: 2.379182, accuracy: 0.148372\n",
      "step: 4000, loss: 2.375359, accuracy: 0.148578\n",
      "step: 4200, loss: 2.371901, accuracy: 0.148653\n",
      "step: 4400, loss: 2.368757, accuracy: 0.148345\n",
      "step: 4600, loss: 2.365886, accuracy: 0.148227\n",
      "step: 4800, loss: 2.363255, accuracy: 0.148477\n",
      "step: 5000, loss: 2.360834, accuracy: 0.148844\n",
      "step: 5200, loss: 2.358600, accuracy: 0.149171\n",
      "step: 5400, loss: 2.356531, accuracy: 0.149034\n",
      "step: 5600, loss: 2.354609, accuracy: 0.149001\n",
      "step: 5800, loss: 2.352821, accuracy: 0.149106\n",
      "step: 6000, loss: 2.351151, accuracy: 0.149250\n",
      "step: 6200, loss: 2.349589, accuracy: 0.149199\n",
      "step: 6400, loss: 2.348125, accuracy: 0.149219\n",
      "step: 6600, loss: 2.346750, accuracy: 0.149200\n",
      "step: 6800, loss: 2.345455, accuracy: 0.149164\n",
      "step: 7000, loss: 2.344234, accuracy: 0.149491\n",
      "step: 7200, loss: 2.343082, accuracy: 0.149397\n",
      "step: 7400, loss: 2.341991, accuracy: 0.149459\n",
      "step: 7600, loss: 2.340958, accuracy: 0.149539\n",
      "step: 7800, loss: 2.339978, accuracy: 0.149780\n",
      "step: 8000, loss: 2.339047, accuracy: 0.149672\n",
      "step: 8200, loss: 2.338161, accuracy: 0.149623\n",
      "step: 8400, loss: 2.337318, accuracy: 0.149613\n",
      "step: 8600, loss: 2.336514, accuracy: 0.149640\n",
      "step: 8800, loss: 2.335746, accuracy: 0.149805\n",
      "step: 9000, loss: 2.335012, accuracy: 0.149847\n",
      "step: 9200, loss: 2.334311, accuracy: 0.149779\n",
      "step: 9400, loss: 2.333639, accuracy: 0.149850\n",
      "step: 9600, loss: 2.332995, accuracy: 0.149850\n",
      "step: 9800, loss: 2.332377, accuracy: 0.149936\n",
      "step: 10000, loss: 2.331784, accuracy: 0.149881\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 定义超参数\n",
    "learning_rate = 0.001\n",
    "training_steps = 10000\n",
    "batch_size = 32\n",
    "display_step = 200\n",
    "\n",
    "# 加载数据\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "x_train, x_test = x_train/255., x_test/255.\n",
    "\n",
    "# 将数据转换成序列的形式\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(5000).batch(batch_size).prefetch(1)\n",
    "\n",
    "# 定义网络结构\n",
    "class RNN(tf.keras.Model):\n",
    "    def __init__(self, num_units, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.num_classes = num_classes\n",
    "        self.rnn_layer = tf.keras.layers.LSTM(self.num_units)\n",
    "        self.fc_layer = tf.keras.layers.Dense(self.num_classes)\n",
    "        \n",
    "    def call(self, x):\n",
    "        # RNN layer\n",
    "        x = self.rnn_layer(x)\n",
    "        # fully connected layer\n",
    "        x = self.fc_layer(x)\n",
    "        return x\n",
    "\n",
    "# 定义模型\n",
    "model = RNN(num_units=64, num_classes=10)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# 定义性能指标\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "# 训练模型\n",
    "for step, (batch_x, batch_y) in enumerate(train_data.take(training_steps), 1):\n",
    "    # 将数据转换成可训练模型输入的格式\n",
    "    batch_x = tf.reshape(batch_x, shape=[-1, 28, 28])\n",
    "    # 计算梯度\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(batch_x)\n",
    "        loss = loss_object(batch_y, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    # 记录性能指标\n",
    "    train_loss(loss)\n",
    "    train_accuracy(batch_y, predictions)\n",
    "    # 显示训练进度\n",
    "    if step % display_step == 0:\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, train_loss.result(), train_accuracy.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: ./logs : 系统找不到指定的路径。\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import shutil\n",
    "import os\n",
    "import random\n",
    "\n",
    "dir_path = './logs'\n",
    "\n",
    "try:\n",
    "    shutil.rmtree(dir_path)\n",
    "except OSError as e:\n",
    "    print(\"Error: %s : %s\" % (dir_path, e.strerror))\n",
    "\n",
    "if not os.path.exists(\"./logs\"):\n",
    "    os.makedirs(\"./logs\")\n",
    "\n",
    "writer = SummaryWriter('./logs')\n",
    "\n",
    "for epoch in range(100):\n",
    "    train_loss = epoch**2+3*epoch + 5*random.uniform(0,100)\n",
    "    writer.add_scalar(\"loss/train\", train_loss, epoch)\n",
    "\n",
    "writer.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
